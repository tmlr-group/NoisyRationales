# noise test
model: gpt-3.5-turbo-0125 # gpt-3.5-turbo-0613 or gemini-pro or mixtral or  llama-2-70b or gpt-4-0125-preview or meta-llama/Meta-Llama-3.1-8B-Instruct
dataset: commonsense # math and symbolic and commonsense 
start_num: 0
test_num: 10
batch_size: 5

## method
method: selfconsistency  # CD-CoT or basemodel, selfconsistency,  smoothllm, selfdenoise, selfpolish, contrastivecot, ISC, SCO, BT

### basemodel, smoothllm, selfdenoise, selfpolish, contrastivecot, ISC
temperature_reason: 1
n_reason: 5

### CD-CoT
use_logged_rephrased_result: False  # for ablation, default to False
use_logged_ICL_result: False  # for ablation, default to False
n_rephrase: 5
temperature_rephrase: 1
topp_rephrase: 1
use_clean_shot: True
c_reason: [3,2] # [5] or [3,2] or [2,2,1] or [1,1,1,1,1]
temp_reason: 1
topp_reason: 1

## subtask
### math
math:
  subtask: base-9

### symbolic
symbolic:
  subtask: equal # equal or longer

## use subfolder_suffix
# subfolder_suffix_path: generated_noise

## use_processed_dataset or use raw dataset
use_processed_dataset: False

### when use_processed_dataset is True
processed_dataset_options:
  # processed dataset path or one of ["default-zeroshot"ï¼Œ "default-clean", "default-(irrelevant|inaccurate)-(easy|medium|hard)-(fixed|random)"]
  processed_dataset_path: default-irrelevant-easy
  n_shots: 3
  using_subset: False
  # processed_dataset_path: default-zeroshot

### when use_processed_datset is False
raw_dataset_options:
  ## in-context 
  if_in_context: True
  n_shots: 0 # clean shots
  # n_weak_shots: 0
  #--- noise setting ---
  if_noise: True
  n_noisy_shots: 3
  noise_type: inaccurate # irrelevant or inaccurate
  noise_ratio: 0.3 # 0.3, 0.5 or 0.8
  noise_semantic_related: 0 # 0-2
  noise_distribution: fixed #fixed or random 

# shuffle_study: True
# shuffle_type: 3

# ICL format
prefix_context: True ## prefix
